### Setup S3 Buckets
For this demo, we will create two different S3 buckets.
In one we will store the content of build directory and in another we will store the data generated by our cassandra database.
The choice of folders is arbitrary and is used to create some content.

Create a bucket spark-job-build and sync build folder with it
```
aws s3 mb s3://spark-job-build
aws s3 sync build s3://spark-job-build
```

Create a bucket spark-job-cql and sync cql folder with it
```
aws s3 mb s3://spark-job-cql
mkdir -p cql
aws s3 sync cql s3://spark-job-cql
```

We will also update the bucket policy for spark-job-cql to enforce the use of certain TLS version.

```
cat > bucket.json <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "EnforceTLSv12orHigher",
      "Principal": {
        "AWS": "*"
      },
      "Action": ["s3:*"],
      "Effect": "Deny",
      "Resource": [
        "arn:aws:s3:::spark-job-cql/*",
        "arn:aws:s3:::spark-job-cql"
      ],
      "Condition": {
        "NumericLessThan": {
          "s3:TlsVersion": 1.2
        }
      }
    }
  ]
}
EOF
```

Once the above snippet is executed to create a policy.json, apply the policy and verify it by retrieving it.

```
aws s3api put-bucket-policy --bucket spark-job-cql --policy file://bucket.json 
aws s3api get-bucket-policy --bucket spark-job-cql
```
The information about support of TLS versions by AWS can be found here.
https://aws.amazon.com/blogs/security/tls-1-2-required-for-aws-endpoints/


Similarly setup the S3 Access ID and Key as environment variables so as to not share it anywhere within this codebase.

It can be stored in either ~/.zshrc or equivalent
```
export AWS_ACCESS_KEY_ID=
export AWS_SECRET_ACCESS_KEY=
```

